---
layout: post
title:  "test article"
date:   2015-09-24 16:35:32
author: Nam Juno
categories: test
tags:	test 
---

<script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

### 테스트용 글

> Stochastic gradient descent is a gradient descent optimization method for minimizing an objective function that is written as a sum of differentiable functions.

When used to minimize the above function, a standard (or "batch") gradient descent method would perform the following iterations :

$$w:=w-\eta\sum_{i=1}^{n}{\nabla Q_i(w)}$$

잘나오는듯(만족!)